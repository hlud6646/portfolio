{% extends "layout.html" %}
{% set active_page = "deep_learning" %}

{% block title %}
Flowers
{% endblock %}

{% block subtitle %}
	<br><br>
	Image Recognition with Tensorflow and keras.
	<img src="/static/images/flowers1.png" alt="sd" width=100%>
{% endblock %}

{% block source %}
	<a href="https://github.com/hlud6646/ds/blob/master/Templates/Image%20Classification%20Example.ipynb">https://github.com/hlud6646/ds/blob/master/Templates/Image Classification Example.ipynb</a>
{% endblock %}


{% block words %}










	This is the first real machine learning project I've written.  It is an image classifier for 
	five different types of flowers.  There's a lot of room for improvement in the model design (accuracy is around 60%) but the focus so far has been building a good workflow as a foundation.  It runs like this:

	<ol>
		<li>The dataset used for this project initially has the structure 
			<pre>
			flowers
			 -> daisy
			 -> ...
			 -> tulip</pre>
			but the required structure is 
			<pre>
			flowers 
			 -> train
			     -> daisy
			     -> ...
			     -> tulip
			 -> test
			     -> daisy
			     -> ...
			     -> tulip</pre>
			Reorganising the data is achieved with a script like 
			<script src="https://gist.github.com/hlud6646/d7571c59fc6a2917b70bc3af1d1e64f7.js"></script>
			The same can be achieved by setting the 
			<code class="language-python">validation_split</code> argument in the 
			<code class="language-python">keras.ImageDataProcessor</code> used to buffer input data
			but I'm ok with doing this beforehand.
		 </li>


		 <li>
		 	Images are loaded (more precicely, configured to be loaded into a flow) in a 
		 	<code class="language-python">keras.ImageDataProcessor</code>.
		 	This method is cool because it allows 
		 	data augmentation to take place with only a few keystrokes.  The idea is that for a 
		 	collection of flowers, you could flip the occasional one left to right and you'd get a 
		 	perfectly reasonable image that could also be used to train the model.
		 	<script src="https://gist.github.com/hlud6646/74c40af322a7b7e67ec4e07341a2959b.js"></script>
		 </li>


		 <li>
		 	It's nice to have a look at the data before going into the deeper stuff. This code genreates the image at the top of the page:
		 	<script src="https://gist.github.com/hlud6646/09a4d13e9ad964594b2e8dd9c8f7daa4.js"></script>
		 </li>






		 <li>
		 	The model needs to be instantiated and configured before it is trained and used.  This is where the real work is.  The rest is basically setup, so naturally this is the part that I understand the least.  
		 	<script src="https://gist.github.com/hlud6646/c0eb212d3c1b355674c7d9f53f6c990c.js"></script>
		 </li>
		 


		 <li>
		 	Time to see some predictions.  The following code predicts the type of 
		 	flower in some pictures that I got from google images.
			<script src="https://gist.github.com/hlud6646/1ecd53e0062471439cf6ac9fe2efed98.js"></script>
			<img src="/static/images/flowers2.png" alt="sd" width=100%>
		</li>
	</ol>

{% endblock %}



