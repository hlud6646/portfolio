{% extends "layout.html" %}
{% set active_page = "deep_learning" %}

{% block title %}
Flowers
{% endblock %}

{% block subtitle %}
	<br><br>
	Image Recognition with Tensorflow and keras.
	<img src="/static/images/flowers1.png" alt="sd" width=100%>
{% endblock %}

{% block source %}
	<a href="https://github.com/hlud6646/ds/blob/master/Templates/Image%20Classification%20Example.ipynb">https://github.com/hlud6646/ds/blob/master/Templates/Image Classification Example.ipynb</a>
{% endblock %}


{% block words %}










	This is the first real machine learning project I've written.  It is an image classifier for 
	five different types of flowers.  There's a lot of room for improvement in the model design (accuracy is around 60%) but the focus so far has been building a good workflow as a foundation.  It runs like this:

	<ol>
		<li>The dataset used for this project initially has the structure 
			<pre>
			flowers
			 -> daisy
			 -> ...
			 -> tulip</pre>
			but the required structure is 
			<pre>
			flowers 
			 -> train
			     -> daisy
			     -> ...
			     -> tulip
			 -> test
			     -> daisy
			     -> ...
			     -> tulip</pre>
			Reorganising the data is achieved with a script like 






<pre><code class="language-python">from pathlib import Path
import shutil
from numpy.random import random

p = Path('.')
(p / 'train').mkdir()
(p / 'valid').mkdir()

validation_split = 0.2

for species in 'daisy dandelion rose sunflower tulip'.split():
	(p / 'train' / species).mkdir()
	(p / 'valid' / species).mkdir()
	for img in (p / species).iterdir():
		if random() < validation_split:
			shutil.copy(str(img), str(p / 'valid' / img))
		else: 
			shutil.copy(str(img), str(p / 'train' / img))
	shutil.rmtree(p / species)</code></pre>







			The same can be achieved by setting the 
			<code class="language-python">validation_split</code> argument in the 
			<code class="language-python">keras.ImageDataProcessor</code> used to buffer input data
			but I'm ok with doing this beforehand.
		 </li>


		 <li>
		 	Images are loaded (more precicely, configured to be loaded into a flow) in a 
		 	<code class="language-python">keras.ImageDataProcessor</code>.
		 	This method is cool because it allows 
		 	data augmentation to take place with only a few keystrokes.  The idea is that for a 
		 	collection of flowers, you could flip the occasional one left to right and you'd get a 
		 	perfectly reasonable image that could also be used to train the model.






<pre><code class="language-python">from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout

import numpy as np
from pathlib import Path

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline

# Variables shared beteween training and validation flows.
prefix = './data/flowers/'
train_path = prefix + 'train'
valid_path = prefix + 'valid'
target_size = (150, 150)

def preprocess_image(image):
    """ From docs for ImageDataGenerator:
            function that will be applied on each input. 
            The function will run after the image is resized and augmented. 
            The function should take one argument: one image (Numpy tensor with rank 3), 
            and should output a Numpy tensor with the same shape.
        This example normalizes 8bit RGB, since TensorFlow Hub image modules expect floats in [0, 1]."""
    return image / 255

# Data augmentation tidily handled by passing args to this constructor.
data_generator = ImageDataGenerator(
    preprocessing_function=preprocess_image,
    vertical_flip=False,
    horizontal_flip=True)

train_flow = data_generator.flow_from_directory(
    train_path,
    target_size=target_size)

valid_flow = data_generator.flow_from_directory(
    valid_path,
    target_size=target_size)</code></pre>
		 </li>








		 <li>
		 	It's nice to have a look at the data before going into the deeper stuff. This code genreates the image at the top of the page:







<pre><code class="language-python"># Nice to see some of the data.
# Display one image from each class, with the supplied label.
images = []
labels = []
for species in [x for x in Path(train_path).iterdir() if x.is_dir()]:
    labels.append(species.name)
    image_paths = list(species.iterdir())
    image_path = image_paths[np.random.randint(len(image_paths))]
    images.append(mpimg.imread(image_path))

fig, ax = plt.subplots(1, 5, figsize=(20, 10))
for i, image in enumerate(images):
    ax[i].imshow(image)
    ax[i].set_title(labels[i])
    ax[i].axis('off')
plt.savefig('flowers1')</code></pre>
		 </li>






		 <li>
		 	The model needs to be instantiated and configured before it is trained and used.  This is where the real work is.  The rest is basically setup, so natrually this is the part that I understand the least.  






<pre><code class="language-python">model = Sequential()
num_classes = 5

# Input layer.
model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',))

# Hidden layers.
for layer in [
    Conv2D(30, (3, 3), activation='relu', strides=5),
    Dropout(.5),
    Flatten(),
    Dense(128, activation='relu'),]:
    model.add(layer)

# Output layer.
model.add(Dense(units=num_classes, activation='softmax'))

epochs = 5

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(
    train_flow,
    epochs=epochs,
    validation_data=valid_flow,
    )</code></pre>
		 </li>
		 


		 <li>
		 	Time to see some predictions.  The following code predicts the type of 
		 	flower in some pictures that I got from google images.





<pre><code class="language-python"># Visualise some predictions. I grabbed these from google images. Some could be in the training 
# set but I would expect most to be fresh.  Some of the flowers belong to classed that the model
# doesn't know.

def predict(image_path):
    """ Make predictions one at a time."""
    image = load_img(image_path, target_size=target_size)
    y_array = model.predict(np.expand_dims(preprocess_image(img_to_array(image)), axis=0))
    return 'daisy dandelion rose sunflower tulip'.split()[y_array.argmax(axis=-1)[0]]    

image_paths = Path('./data/flowers/test').iterdir()

fig, ax = plt.subplots(5, 5, figsize=(20, 10))
for i, path in enumerate(image_paths):
    if i >= 25:
        break
    ax[i // 5, i % 5].imshow(mping.imread(path))
    ax[i // 5, i % 5].set_title(predict(path))
    ax[i // 5, i % 5].axis('off')
plt.savefig('flowers2')</code></pre>
	<img src="/static/images/flowers2.png" alt="sd" width=100%>
	</li>





{% endblock %}



